---
title: "DS4001 Final Project"
author: "Alex Shen, Andrew Niu"
date: "5/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

# Question

#### **How can we distinguish fake news from real news?**

We've all been told growing up, "Don't believe everything you read on the Internet." In the past, this simply meant avoiding obvious scams and hoaxes, like emails from Nigerian princes suspiciously promising you a share of their wealth. However, in this day and age, the proliferation of digital media in modern society has enabled a far more insidious practice: the writing and mass distribution of so-called "news" articles that *seem* true, and in fact may even incorporate some truthful elements, to push false or misleading claims. 

As Cathy O'Neil warned us in *Weapons of Math Destruction*, "about two-thirds of American adults have a profile on Facebook. They spend thirty-nine minutes a day on the site, only four minutes less than they dedicate to face-to-face socializing. Nearly half of them, according to a Pew Research Center report, count on Facebook to deliver at least some of their news..." It goes without saying that Facebook is not exactly a hub of reputable reporting, so the fact that this many people get their news from such an unreliable platform is deeply concerning for anyone concerned about having a well-informed populace. Thus, we wanted to explore, in a data-driven way, what characterizes fake news and how we might be able to prevent it from tricking us. 

# Exploratory Data Analysis

```{r libraries}
library(tidytext)
library(readr)
library(dplyr)
library(lubridate)
library(scales)
library(tidyr)
library(stringr)
library(ggplot2)
library(gridExtra)
library(textdata)
library(purrr)
library(broom)
```

First, we load in the data.

```{r load-data}

real_news = read_csv("True.csv")
fake_news = read_csv("Fake.csv")
data = bind_rows(real_news %>% mutate(truth = "Real"),
                 fake_news %>% mutate(truth = "Fake")) %>% 
  mutate(formatted_date = mdy(date))

```

The first thing we do with the dataset is clean it in order to make it possible for us to perform text analysis. This means running it through a "tokenizer," which breaks up the raw text data into individual words (and other components/"tokens", but mostly just words). Next, we filter out numbers and "stop words" — these are words that are syntactically necessary, but don't actually contribute to a sentences' meaning, like "the", "a", etc. Once we clean up our data, we make a dataframe containing the frequencies of each word.

```{r tokenize, cache=TRUE}
cleaned = data %>% 
  unnest_tokens(word, text, token="words") %>%
  anti_join(stop_words) %>% 
  filter(!str_detect(word, "[.:0-9]")) #omits strings with any of the characters in the brackets

```

Using our cleaned data, we can generate a dataframe that holds the frequencies of each word grouped by real vs. fake news. Note that this value is represented by `n`, as opposed to `total` which holds the total number of words contained in fake/real news articles in the dataset.  

```{r calc_freqs}
frequency <- cleaned %>% 
  group_by(truth) %>% 
  count(word, sort = TRUE) %>% 
  left_join(cleaned %>% 
              group_by(truth) %>% 
              summarise(total = n()))

head(frequency, 5)
```

## Time window (??)

To understand the timeframe of our dataset, we graphed a simple histogram of the dates that the articles were published.

```{r plot_dates}
ggplot(data, aes(x=formatted_date, fill=truth)) +
  geom_histogram(position="identity", bins=25, show.legend=FALSE) +
  facet_wrap(~truth, ncol=1) + 
  labs(x="Date", y="Count") +
  scale_fill_manual(values=c("#FF4242", "#2BFF2B"))

```

As you can see, we're working with articles spanning from early 2015 to the end of 2018. Looking at general trends, it seems like fake news rapidly jumped in 2016 and has been gradually declining ever since. The most likely explanation for this is simply the 2016 presidential election, since presidential election years typically always have increased levels of political awareness and activity. With more people getting interested in politics, a market appears for flashy clickbait articles that don't always stand up to scrutiny. We suspect that the identities of the candidates who ran in that particular election, Hillary Clinton and Donald Trump, who were both quite controversial, fueled this spike to some extent, but we're unable to confirm this hypothesis at this time. 

By comparison, real news seems to have been fairly consistent throughout 2016 and most of 2017, abruptly increasing by a huge margin at the end of 2017 for some reason, but then declining shortly after peaking. With the obvious exception of late 2017, this consistent trend also makes sense — by comparison to fake news, which is often written by smaller organizations whose popularity (and thus ability to create more content) wanes and waxes with presidential election years, "real" news tends to come from mainstream media outlets, who are much better established and have consistent readership. Since there's always some news that needs to be reported, professional journalists should be able to output more or less the same amount of content regardless of the era they're in. 

We're not certain as to why the amount of articles jumped so drastically in late 2017 and then declined almost immediately after, but it could simply be sampling bias — the creator of this dataset may have just found it more convenient to pull more recent articles. It could even be that the increase in reported fake news articles we found to have occured in early 2016 was simply the result of increased awareness as the presidential campaign season progressed, and not an actual dramatic increase in fake news. Since we only have one dataset, we can't really know the answer to these questions.

## Word Frequencies

**we wanted to understand word freqs for some reason**

The simplest way ~~to do this~~ was to take the most frequent words from both the fake news and real news categories and examine both their individual frequencies and the distribution amongst these words.

```{r freqs}
top_words = frequency %>% 
  arrange(desc(n)) %>%
  group_by(truth) %>% slice(1:5) # slice top 5 from both real and fake groups

# due to the way slice works, the first 5 elements in top_words
# will be from fake news and the last 5 will be from real news
top_fake = top_words[1:5,] 
top_real = top_words[6:10,]

top_words_plot = function(data, color_hex){ # template graph
  return(ggplot(top_fake, aes(x=reorder(word,n), y=n)) +
           geom_col(fill=color_hex) +
           facet_wrap(~truth) +
           theme(axis.text.x = element_text(angle = 15, hjust = 1)) +
           labs(x="Word", y="Frequency") +
           ylim(0, 80000))
}

fake_plot = top_words_plot(top_fake, "#FF4242") # hex code for red
real_plot = top_words_plot(top_real, "#2BFF2B") # hex code for green

grid.arrange(fake_plot, real_plot, ncol=2)
```

As you can see, the words "Trump" and "President" are both frequently included in both fake and real news. This is, of course, not particularly surprising. Any US president would naturally be at or near the top of a word count of a dataset containing primarily American news, but this doesn't explain why Trump's name appears *so much more* than any other word in fake news particularly, when the gap is significantly closer in real news. Our guess is that Trump is simply an especially polarizing figure, so demagogues on both sides of the political aisle have an incentive to constantly invoke his name to stir up either support or opposition of the president.

**fake media focus on people vs. institutions of government**

"Obama" and "Clinton" also show up prominently, which makes sense given that Obama was the previous president and Hillary ran essentially as his successor. Both are quite controversial in right-wing media (especially with extreme sources who are likely to create fake news), and the election year where both were prominent in mainstream political discourse spans a large portion of the dataset, so both of them were naturally mentioned plenty of times in fake news.

Other than President Trump, real news covers more mundane topics — "house" (presumably just part of "House of Representatives" or "White House"), "government," and "Reuters" (a prominent international news organization) round out our top 5 words. This also lines up with what we expected, because a lot of the news isn't supposed to be flashy; a lot of important reporting is done on the complex mechanics of government, which may not be interesting to a mainstream audience.


## Words over time

We then wondered how the top word frequencies had changed over time — our first guess was that words like "Hillary" and "Clinton" would have gone down dramatically after she lost the 2016 election, whereas Trump, having ascended to the presidency, would naturally have mentions of his name increase by a great deal.

In order to definitively answer this question, we have to look at which words have seen their frequencies change the most dramatically during the time period. Our first step is to split the word token data into one-month chunks, where we can see both the number of times a particular word was used in a month (`count`), how many times that word was used in total (`word_total`), and how many words were used in that particular month (`month_total`).

```{r words_over_time_data, cache=TRUE}
words_over_time = cleaned %>% 
  mutate(time_floor = floor_date(formatted_date, unit = "1 month")) %>% 
  count(time_floor, truth, word) %>% 
  group_by(truth, time_floor) %>% 
  mutate(month_total = sum(n)) %>% 
  group_by(truth,word) %>% 
  mutate(word_total = sum(n)) %>% 
  ungroup() %>% 
  rename(count = n) %>% 
  filter(word_total > 18000) # only look at words that have been used >18000 times

head(words_over_time, 5) # just an example
```

The next step is to "nest" our data, which means that we consolidate all our monthly data for each word and store it in a single row so that each word only has one row representing it. This seems unnecessarily arcane, but it allows us to generate models that tell us how much each word changed over time. Computing models for each and every word is quite computationally expensive, which is why we filtered out any word that had a `word_total` of less than 18,000 uses.

```{r words_over_time_nesting, cache=TRUE,}
nested_data = words_over_time %>% 
  nest(-word, -truth)

nested_models = nested_data %>% 
  mutate(models = map(data, ~ glm(cbind(count,month_total) ~ time_floor, ., family="binomial")))
```

Once we have our models, it becomes a simple matter of unnesting the data and picking out which ones are actually statistically significant and tossing everything else out. In our case, every word's model had a p-value of less than 0.05, so we can move forward smoothly. 

```{r words_over_time_graph}
slopes <- nested_models %>%
  mutate(models = map(models, tidy)) %>%
  unnest(cols = c(models)) %>%
  filter(term == "time_floor") %>%
  mutate(adjusted.p.value = p.adjust(p.value))

top_slopes <- slopes %>% 
  filter(adjusted.p.value < 0.05)
```

After all that number crunching, the only thing we have left to do is to graph our real and fake news data and compare them. 

```{r plot_freqtime_function, include=FALSE}
plot_freqtime = function(truth_val){
  freqs = words_over_time %>%
    inner_join(top_slopes, by = c("word", "truth")) %>%
    filter(truth == truth_val) 
  
  ggplot(freqs, aes(time_floor, count/month_total, color = word)) +
    geom_line(size = 1.3) +
    labs(x = NULL,
         y = "Word frequency (as a percent of all words used)",
         title=paste0("Word Frequencies Over Time in ",truth_val," News")) +
    scale_y_continuous(limits=c(0,0.028), breaks=seq(0,0.025,0.005)) +
    guides(word=guide_legend("Top Words"))
}
```

## {.tabset}

### Real News Words Over Time
```{r real_graph}
plot_freqtime("Real")
```


### Fake News Words Over Time
```{r fake_graph}
plot_freqtime("Fake")
```

Here, the most interesting developments are clearly Trump and Clinton, the two 2016 presidential contenders. We can observe that while fake news about Clinton dropped off dramatically after her loss (as she was no longer in the public eye), Trump has consistently had the most mentions in fake news

# Sentiment Analysis Methods

As interesting as word frequencies are, they can't actually give us that much information as to whether or not a given article is real or fake. That's where sentiment analysis comes in, where we figure out the "sentiment" (feeling) conveyed by each word and tally up the most common sentiments expressed by both real and fake news. We can measure sentiment in two different ways: AFINN, where sentiment is just indexed on a scale of -5 to 5 (negative to positive emotion), and NRC, which associates words with common emotions like fear, anger, and sadness. 

A common guess might be that fake news, with its trend towards clickbait-style content, might have more extreme sentiments, but let's see how that bears out in the data.

```{r sentiments, cache=TRUE}

# sent_df: dataframe with sentiment values
# sentiment: entiment label, "value" for afinn and "sentiment" for nrc
# This function takes in a dataframe with sentiment values and outputs the frequency of each factor for both real and fake news articles.
get_freq = function(sent_df, sentiment){
  # this is a quirk with R function parameters
  # need to create a new column called sentiment set equal to the column of the string passed into the variable sentiment
  sent_df$sentiment = sent_df[[sentiment]] 
  counts = sent_df %>% # Get the counts of each factor grouped by truth
    group_by(truth) %>%
    count(sentiment, sort = TRUE)
  totals = sent_df %>% # get total occurrences for real and fake
    group_by(truth) %>%
    summarise(total=n())
  frequency = counts %>% # combine dataframes and calculate frequency
    left_join(totals) %>%
    mutate(freq = n/total)
  return(frequency)
}

plot_sentiments = function(dataset, title_str){
  return(ggplot(dataset, aes(x=sentiment, y=freq, fill=truth)) + 
           geom_bar(stat="identity",position="dodge") + 
           labs(title=title_str, y="Frequency (as a percentage of total)", x="Sentiment") +
           scale_fill_manual(values=c("#FF4242", "#2BFF2B")) +
           scale_y_continuous(labels = function(x) paste0(x*100, "%"))) +
    theme(legend.title = element_blank()) 
}
sentiment_afinn = cleaned %>% 
  inner_join(get_sentiments("afinn"))
abs = sentiment_afinn %>%
  mutate(value = abs(value))
sentiment_nrc = cleaned %>% 
  inner_join(get_sentiments("nrc"))
```

### {.tabset}

#### AFINN

It appears that real news articles have a higher frequency of moderate sentiment values, whereas fake news articles. It's also worth noting that fake articles lean more towards negatively charged words, whereas real news articles seem to be a little less skewed.

```{r afinn,cache=TRUE}
plot_sentiments(get_freq(sentiment_afinn, "value"), "AFINN Sentiments") + 
  scale_x_continuous(limits=c(-5,5), breaks=seq(-5,5,1))
```

#### AFINN Absolute Value

If we take the absolute value of the AFINN score, we can isolate the overall strength of sentiment in our text. We can see even more clearly that real news articles have a higher frequency of moderate AFFFIN values of 1 and 2, whereas fake news articles tend to use more charged language.

```{r abs_value, cache=TRUE}
plot_sentiments(get_freq(abs, "value"), "AFINN Sentiments (Absolute Values)") + 
  scale_x_continuous(limits=c(0,5), breaks=seq(0,5,1))
```

#### NRC

Our NRC sentiment analysis gives us a little more specificity to our analysis while also confirming our findings from the AFINN analysis. Fake news articles have higher frequencies of negatively charged words, especially those of anger, disgust, and general negative sentiment. At the same time, they have lower occurrences of positivity and trust when compared to real news articles.

```{r nrc, cache=TRUE}
plot_sentiments(get_freq(sentiment_nrc, "sentiment"), "NRC Sentiments")
```

### Title vs. Article

Title Data
```{r titledata}
titles = data %>%
  unnest_tokens(word, title, token="words") %>%
  anti_join(stop_words) %>%
  filter(!str_detect(word, "[.:0-9]"))
```

### {.tabset}

When we run the same sentiment analysis on the titles of our articles, we get very similar results. However, the differences seem to be more exaggerated for our titles than the actual content of our articles. This trend confirms our hypotheses, as authors of fake news articles tend to use flashy and clickbaity titles in hopes of luring in potential readers. 

#### AFINN

```{r title_afinn, cache=TRUE}

title_afinn = titles %>%
  inner_join(get_sentiments("afinn"))
plot_sentiments(get_freq(title_afinn, "value"), "Title AFINN Sentiments")
```

#### AFINN Absolute Value

```{r title_abs, cache=TRUE}
title_abs = title_afinn %>%
  mutate(value = abs(value))
plot_sentiments(get_freq(title_abs, "value"), "Title AFINN Sentiments (Absolute Values)")
```

#### NRC

```{r title_nrc, cach=TRUE}
title_nrc = titles %>%
  inner_join(get_sentiments("nrc"))
plot_sentiments(get_freq(title_nrc, "sentiment"), "Title NRC Sentiments")
```

### Comparison

To further investigate the difference in sentiment, or perhaps exaggeration, of our titles, we compare them directly to the sentiment of the articles themselves.

This is a helper function designed to combine a title sentiment dataset and an article sentiment dataset. The key metric here is the difference in frequency of each sentiment value between real and fake articles. A positive value indicates that there was a higher occurrence of the sentiment value in real articles, whereas a negative value indicates a higher occurrence in fake articles. We want to compare the differences of the real and fake articles between the titles of the articles and the articles themselves.

```{r combined}
# title: sentiment data on titles
# article: sentiment data on articles
# sentiment: sentiment label, "value" for afinn and "sentiment" for nrc
# This function takes in two dataframes with sentiment values and outputs a new dataframe.
# Each row in this dataframe represents the difference in sentiment value frequencies between
# real and fake news articles for either the title or article body.
title_vs_article = function(title, article, sentiment){
  #get the frequencies dataframes for both title and article
  title = get_freq(title, sentiment) %>% mutate(text="title") # label where the text is from
  article = get_freq(article, sentiment) %>% mutate(text="article")
  combined = rbind(title,article)
  combined = combined %>%
    group_by(text) %>%
    select(truth, sentiment, freq) %>%
    spread(truth, freq) %>% # separate real and fake values into separate columns
    arrange(Real, Fake) %>%
    mutate(Real = replace_na(Real,0), # replace na values with 0
           Fake = replace_na(Fake,0),
           diff = Real-Fake) # take the difference in frequency between real and fake occurrences
  return(combined)
}
```

Another helper function to graph all the combined sentiments with consistent styling:
```{r combined_plotter}
plot_combined_sentiments = function(dataset, title_str){
  ggplot(dataset, aes(x=sentiment, y=diff, fill=text)) +
    geom_bar(stat="identity",position="dodge") + 
    labs(title=title_str, x="Sentiment", y="Difference in Percentage Frequencies (Real-Fake)") + 
    scale_fill_manual(values=c("#FF4B2B", "#3A82FF")) +
    scale_y_continuous(labels = function(x) paste0(x*100, "%")) +
    theme(legend.title = element_blank()) 
}

```

### {.tabset}

#### AFINN

As seen in the earlier graphs, fake news articles are more charged, particularly with negative sentiment, but we can also observe the difference in magnitude between the titles and the articles themselves. In every category except for neutral positive words, the title has a greater magnitude of difference than the articles. This essentially means that the level of bias is even greater in fake news titles when compared to the level of bias in fake news articles.

```{r AFINN_combined}
plot_combined_sentiments(title_vs_article(title_afinn, sentiment_afinn, "value"), 
                         "Title vs. Article AFINN Sentiment") +
  scale_x_continuous(limits=c(-5,5), breaks=seq(-5,5,1))
```

#### AFINN Absolute Value

Similar to the absolute value graphs above, this graph further emphasizes the difference in level of bias. The difference between real and fake news titles are even more polarized than the articles themselves.

```{r abs_combined}
plot_combined_sentiments(title_vs_article(title_abs, abs, "value"), 
                         "Title vs. Article AFINN Sentiment (Absolute Values)") + 
  scale_x_continuous(limits=c(0,5), breaks=seq(0,5,1))
```

#### NRC

We again see that fake news articles bias more towards negative emotions with the titles of these fake news articles being even more negative. We can see the same trend with real news articles and positivity and trust.

```{r NRC_combined}
plot_combined_sentiments(title_vs_article(title_nrc, sentiment_nrc, "sentiment"), 
                         "Title vs. Article NRC Sentiment")
```

## Conclusions

## Future Work

One major issue we ran into while working is that we were completely uncertain as to how this dataset was created, and thus unsure that it was reliably sampled. With a subject as polarized as what constitutes "fake" news, it's important to have a trustworthy dataset to base your analysis off of. However, there were some notable issues with our particular dataset that made us doubt its legitimacy. For example, the incredible spike of real news datapoints in late 2017 and the dramatic drop of mentions of "Trump," who as the President should always be quite commonly featured in mainstream news articles, were both phenomena that we couldn't think of an explanation for, making us believe it was the product of unreliable sampling by the creator of the dataset. The unusually high occurence of "Reuters" a new outlet that while well-known, isn't exactly the first news source people think of, is also somewhat suspicious. 