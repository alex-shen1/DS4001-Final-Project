---
title: "DS4001 Final Project"
author: "Alex Shen, Andrew Niu"
date: "5/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question
**How can we distinguish fake news from real news?**

We've all been told growing up, "Don't believe everything you read on the Internet." In the past, this simply meant avoiding obvious scams and hoaxes, like emails from Nigerian princes suspiciously promising you a share of their wealth. However, in this day and age, the proliferation of digital media in modern society has enabled a far more insidious practice: the writing and mass distribution of so-called "news" articles that *seem* true, and in fact may even incorporate some truthful elements, to push false or misleading claims. 

## Exploratory Data Analysis

```{r libraries, message=FALSE, warning=FALSE}
library(tidytext)
library(readr)
library(dplyr)
library(lubridate)
library(scales)
library(tidyr)
library(stringr)
library(ggplot2)
library(gridExtra)
library(textdata)
library(purrr)
library(broom)
```



```{r load-data, message=FALSE, warning=FALSE}

real_news = read_csv("True.csv")
fake_news = read_csv("Fake.csv")
data = bind_rows(real_news %>% mutate(truth = "Real"),
                 fake_news %>% mutate(truth = "Fake")) %>% 
  mutate(formatted_date = mdy(date))

```

```{r tokenize, cache=TRUE, message=FALSE}
cleaned = data %>% 
  unnest_tokens(word, text, token="words") %>%
  anti_join(stop_words) %>% 
  filter(!str_detect(word, "[.:0-9]"))

frequency <- cleaned %>% 
  group_by(truth) %>% 
  count(word, sort = TRUE) %>% 
  left_join(cleaned %>% 
              group_by(truth) %>% 
              summarise(total = n()))
```

## Time window (??)

Obviously, with any data analysis it's important to understand the data you're working with. 
```{r plot_dates, warning=FALSE}
ggplot(data, aes(x=formatted_date, fill=truth)) +
  geom_histogram(position="identity", bins=25, show.legend=FALSE) +
  facet_wrap(~truth, ncol=1) + 
  labs(x="Date", y="Count")

```

As you can see, we're working with articles spanning from early 2015 to the end of 2018. Looking at general trends, it seems like fake news spiked in 2016 and has been gradually declining ever since. The most likely explanation for this is simply the 2016 presidential election, since presidential election years typically always have increased levels of political awareness and activity. With more people getting interested in politics, a market appears for flashy clickbait articles that don't always stand up to scrutiny. We suspect that the identities of the candidates who ran in that particular election, Hillary Clinton and Donald Trump, who were both quite controversial, fueled this spike to some extent, but we're unable to confirm this hypothesis at this time. 

**caveat w/ saying maybe the entire trend is just result sampling** 

By comparison, real news seems to have been fairly consistent throughout 2016 and most of 2017, abruptly increasing by a huge margin at the end of 2017 for some reason, but then declining shortly after peaking. With the obvious exception of late 2017, this consistent trend also makes sense — by comparison to fake news, which is often written by smaller organizations whose popularity (and thus ability to create more content) wanes and waxes with presidential election years, "real" news tends to come from mainstream media outlets, who are much better established and have consistent readership. Since there's always some news that needs to be reported, professional journalists should be able to output more or less the same amount of content regardless of the era they're in. We're not certain as to why the amount of articles jumped so drastically in late 2017 and then declined almost immediately after, but it could simply be sampling bias — the creator of this dataset may have just found it more convenient to pull more recent articles.

## Word Frequencies

```{r freqs}
top_words = frequency %>% 
  arrange(desc(n)) %>%
  group_by(truth) %>% slice(1:5)

top_fake = top_words[1:5,]
top_real = top_words[6:10,]


fake_plot = ggplot(top_fake, aes(x=reorder(word,n), y=n)) +
  geom_col(fill="#FF4242") +
  facet_wrap(~truth) +
  theme(axis.text.x = element_text(angle = 15, hjust = 1)) +
  labs(x="Word", y="Frequency") +
  ylim(0, 80000)

real_plot = ggplot(top_real, aes(x=reorder(word,n), y=n)) +
  geom_col(fill="#2BFF2B") +
  facet_wrap(~truth) +
  theme(axis.text.x = element_text(angle = 15, hjust = 1)) +
  labs(x="Word", y="Frequency") +
  ylim(0, 80000)

grid.arrange(fake_plot, real_plot, ncol=2)
```

As you can see, the words "Trump" and "President" are both frequently included in both fake and real news. This is, of course, not particularly surprising. Any US president would naturally be at or near the top of a word count of a dataset containing primarily American news, but this doesn't explain why Trump's name appears *so much more* than any other word in fake news particularly, when the gap is significantly closer in real news. Our guess is that Trump is simply an especially polarizing figure, so demagogues on both sides of the political aisle have an incentive to constantly invoke his name to stir up either support or opposition of the president.
**include note on how trump is SO MUCH MORE prominent in fake news vs. everything else**
**fake media focus on people vs. institutions of government**
"Obama" and "Clinton" also show up prominently, which makes sense given that Obama was the previous president and Hillary ran essentially as his successor. Both are quite controversial in right-wing media (especially with extreme sources who are likely to create fake news), and the election year where both were prominent in mainstream political discourse spans a large portion of the dataset, so both of them were naturally mentioned plenty of times in fake news.

Other than President Trump, real news covers more mundane topics — "house" (presumably just part of "White House"), "government," and "Reuters" (a prominent international news organization) round out our top 5 words. This also lines up with what we expected, because a lot of the news isn't supposed to be flashy; a lot of important reporting is done on the complex mechanics of government, which may not be interesting to a mainstream audience.


## Words over time

We then wondered if the top word frequencies had changed over time — our first guess was that words like "Hillary" and "Clinton" would go down after she lost the 2016 election, whereas "Trump" would go up. 
```{r words_over_time_data, message=FALSE, cache=TRUE}
words_over_time = cleaned %>% 
  mutate(time_floor = floor_date(formatted_date, unit = "1 month")) %>% 
  count(time_floor, truth, word) %>% 
  group_by(truth, time_floor) %>% 
  mutate(time_total = sum(n)) %>% 
  group_by(truth,word) %>% 
  mutate(word_total = sum(n)) %>% 
  ungroup() %>% 
  rename(count = n) %>% 
  filter(word_total > 18000)
```

```{r words_over_time_nesting, warning=FALSE, cache=TRUE,}
nested_data = words_over_time %>% 
  nest(-word, -truth)

nested_models = nested_data %>% 
  mutate(models = map(data, ~ glm(cbind(count,time_total) ~ time_floor, ., family="binomial")))
```

```{r words_over_time_graph, warning=FALSE}
slopes <- nested_models %>%
  mutate(models = map(models, tidy)) %>%
  unnest(cols = c(models)) %>%
  filter(term == "time_floor") %>%
  mutate(adjusted.p.value = p.adjust(p.value))

top_slopes <- slopes %>% 
  filter(adjusted.p.value < 0.05)
```

This is a just helper function to help us graph the distributions over time for both real and fake news with the same fundamental logic.
```{r plot_freqtime_function}
plot_freqtime = function(truth_val){
  freqs = words_over_time %>%
    inner_join(top_slopes, by = c("word", "truth")) %>%
    filter(truth == truth_val) 
  
  ggplot(freqs, aes(time_floor, count/time_total, color = word)) +
    geom_line(size = 1.3) +
    labs(x = NULL,
         y = "Word frequency (as a percent of all words used)",
         title=paste0("Word Frequencies Over Time in ",truth_val," News")) +
    scale_y_continuous(limits=c(0,0.028), breaks=seq(0,0.025,0.005)) +
    guides(word=guide_legend("Top Words"))
}
```

Here we use the helper function to generate our graphs.

## {.tabset}

### Real News Words Over Time
```{r real_graph, warning=FALSE}
plot_freqtime("Real")
```


### Fake News Words Over Time
```{r fake_graph, warning=FALSE}
plot_freqtime("Fake")
```

Here, the most interesting developments are clearly Trump and Clinton, the two 2016 presidential contenders. We can observe that while fake news about Clinton dropped off dramatically after her loss (as she was no longer in the public eye), Trump has consistently had the most fake news 

## Sentiment Analysis

However, as interesting as word frequencies are, they can't actually give us that much information as to whether or not a given article is real or fake. That's where sentiment analysis comes in, where we figure out the "sentiment" (feeling) conveyed by each word and tally up the most common sentiments expressed by both real and fake news. We can measure sentiment in two different ways: AFFIN, where sentiment is just indexed on a scale of -5 to 5 (negative to positive emotion), and NRC, which associates words with common emotions like fear, anger, and sadness. 

A common guess might be that fake news, with its trend towards clickbait-style content, might have more extreme sentiments, but let's see how that bears out in the data.

```{r sentiments, cache=TRUE}
get_freq = function(sent_df, sentiment){
  sent_df$sentiment = sent_df[[sentiment]]
  counts = sent_df %>%
    group_by(truth) %>%
    count(sentiment, sort = TRUE)
  totals = sent_df %>%
    group_by(truth) %>%
    summarise(total=n())
  frequency = counts %>%
    left_join(totals) %>%
    mutate(freq = n/total)
  return(frequency)
}

plot_sentiments = function(dataset, title_str){
  return(ggplot(dataset, aes(x=sentiment, y=freq, fill=truth)) + 
           geom_bar(stat="identity",position="dodge") + 
           labs(title=title_str, y="Frequency (as a percentage of total)", x="Sentiment") +
           scale_fill_manual(values=c("#FF4242", "#2BFF2B")) +
           scale_y_continuous(labels = function(x) paste0(x*100, "%")))
}
sentiment_affin = cleaned %>% 
  inner_join(get_sentiments("afinn"))
plot_sentiments(get_freq(sentiment_affin, "value"), "AFFIN Sentiments") + scale_x_continuous(limits=c(-5,5), breaks=seq(-5,5,1))

abs = sentiment_affin %>%
  mutate(value = abs(value))
plot_sentiments(get_freq(abs, "value"), "AFFIN Sentiments (Absolute Values)") + scale_x_continuous(limits=c(0,5), breaks=seq(0,5,1))

sentiment_nrc = cleaned %>% 
  inner_join(get_sentiments("nrc"))
plot_sentiments(get_freq(sentiment_nrc, "sentiment"), "NRC Sentiments")
```

### Title vs. Text

```{r}
# title: sentiment data on titles
# article: sentiment data on articles
# sentiment: sentiment label, "value" for affin and "sentiment" for nrc
# This function takes in two dataframes with sentiment values and outputs a new dataframe.
# Each row in this dataframe represents the difference in sentiment value frequencies between
# real and fake news articles for either the title or article body.
title_vs_article = function(title, article, sentiment){
  #get the frequencies dataframes for both title and article
  title = get_freq(title, sentiment) %>% mutate(text="title") # label where the text is from
  article = get_freq(article, sentiment) %>% mutate(text="article")
  combined = rbind(title,article)
  combined = combined %>%
    group_by(text) %>%
    select(truth, sentiment, freq) %>%
    spread(truth, freq) %>% # separate real and fake values into separate columns
    arrange(real, fake) %>%
    mutate(real = replace_na(real,0), # replace na values with 0
           fake = replace_na(fake,0),
           diff = real-fake) # take the difference in frequency between real and fake occurrences
  return(combined)
}

titles = data %>%
  unnest_tokens(word, title, token="words") %>%
  anti_join(stop_words) %>%
  filter(!str_detect(word, "[.:0-9]"))


title_affin = titles %>%
  inner_join(get_sentiments("afinn"))
plot_sentiments(get_freq(title_affin, "value"), "test")
# ggplot(get_freq(title_affin, "value"), aes(x=sentiment, y = freq, fill=truth)) +
#   geom_bar(stat="identity",position="dodge")
title_abs = title_affin %>%
  mutate(value = abs(value))
# ggplot(get_freq(title_abs, "value"), aes(x=sentiment, y = freq, fill=truth)) +
#   geom_bar(stat="identity",position="dodge")
title_nrc = titles %>%
  inner_join(get_sentiments("nrc"))
# ggplot(get_freq(title_nrc, "sentiment"), aes(x=sentiment, y = freq, fill=truth)) +
#   geom_bar(stat="identity",position="dodge")



plot_combined_sentiments = function(dataset, title_str){
  ggplot(dataset, aes(x=sentiment, y=diff, fill=text)) +
  geom_bar(stat="identity",position="dodge")
}
# ggplot(title_vs_article(title_affin, sentiment_affin, "value"), aes(x=sentiment, y=diff, fill=text)) +
#   geom_bar(stat="identity",position="dodge")
# ggplot(title_vs_article(title_abs, abs, "value"), aes(x=sentiment, y=diff, fill=text)) +
#   geom_bar(stat="identity",position="dodge")
# ggplot(title_vs_article(title_nrc, sentiment_nrc, "sentiment"), aes(x=sentiment, y=diff, fill=text)) +
#   geom_bar(stat="identity",position="dodge")


```

## Conclusions

## Future Work

One major issue we ran into while working is that we were completely uncertain as to how this dataset was created, and thus unsure that it was reliably sampled. With a subject as polarized as what constitutes "fake" news, it's important to have a trustworthy dataset to base your analysis off of. However, there were some notable issues with our particular dataset that made us doubt its legitimacy. For example, the incredible spike of real news datapoints in late 2017 and the dramatic drop of mentions of "Trump," who as the President should always be quite commonly featured in mainstream news articles, were both phenomena that we couldn't think of an explanation for, making us believe it was the product of unreliable sampling by the creator of the dataset. The unusually high occurence of "Reuters" a new outlet that while well-known, isn't exactly the first news source people think of, is also somewhat suspicious. 